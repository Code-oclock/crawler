Проект представляет собой высокопроизводительный многопоточный «краулер» файловой системы, построенный по принципам Map-Reduce. Его главная задача — обойти заданную корневую папку, считать и обработать содержимое всех файлов, а затем аккумулировать результаты в единое значение.

Ключевые компоненты:

1. Pool — универсальный пул воркеров с тремя режимами работы:

   - List (поиск) — рекурсивно собирает список файлов и папок;

   - Transform (преобразование) — читает и парсит каждый файл в объект заданного типа;

   - Accumulate (аккумуляция) — объединяет полученные объекты в промежуточные результаты.

2. Crawler — обёртка над пулом, которая управляет сквозным процессом:

   - Search: находит все файлы под корнем;

   - Process: в каждом файле десериализует данные (например, из JSON) в объекты типа T;

   - Reduce: объединяет все объекты в итоговое значение R с помощью ассоциативной функции Combiner.

3. Конфигурация — позволяет гибко задавать число параллельных воркеров для поиска, обработки и аккумуляции, чтобы подогнать под доступные ресурсы.

Особенности:

   - Полностью неблокируемая (без буферов) работа по каналам Go.

   - Корректная отмена через context.Context.

   - Потокобезопасность функций Transformer и Accumulator.

   - Возможность масштабирования на большие объёмы данных, которые умещаются в память.
